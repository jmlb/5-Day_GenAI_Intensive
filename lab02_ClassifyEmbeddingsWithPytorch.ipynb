{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec189393-b95a-4bd9-b8c7-81a2acc2eb75",
   "metadata": {},
   "source": [
    "# Day 2 - Classifying embeddings with Keras and the Gemini API\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome back to the Kaggle 5-day Generative AI course. In this notebook, you'll learn to use the embeddings produced by the Gemini API to train a model that can classify newsgroup posts into the categories (the newsgroup itself) from the post contents.\n",
    "\n",
    "This technique uses the Gemini API's embeddings as input, avoiding the need to train on text input directly, and as a result it is able to perform quite well using relatively few examples compared to training a text model from scratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c145e3e-ee5a-4f19-9724-f5c19d5541da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64c233f4-ba23-4d89-b704-69575797e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "gemini_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=gemini_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed13fa-10c0-4e82-ad64-f5e5380389e4",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "\n",
    "The 20 Newsgroups Text Dataset contains 18,000 newsgroups posts on 20 topics divided into training and test sets. The split between the training and test datasets are based on messages posted before and after a specific date. For this tutorial, you will use sampled subsets of the training and test sets, and perform some processing using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5b1d1a-e547-49f5-be89-9d4011a00b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "# View list of class names for dataset\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c041cf66-43ca-49fe-aad5-61e4e6f512d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf81bf5-e849-4d8d-9f65-4ab9b5e020d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Start by preprocessing the data for this tutorial in a Pandas dataframe. To remove any sensitive information like \n",
    "names and email addresses, you will take only the subject and body of each message. This is an optional step that transforms \n",
    "the input data into more generic text, rather than email posts, so that it will work in other contexts.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    # Extract only the subject and body\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    # Strip any remaining email addresses\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    # Truncate each entry to 5,000 characters\n",
    "    text = text[:5000]\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    # Put data points into dataframe\n",
    "    df = pd.DataFrame(\n",
    "        {\"Text\": newsgroup_dataset.data, \"Label\": newsgroup_dataset.target}\n",
    "    )\n",
    "    # Clean up the text\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    # Match label to target name index\n",
    "    df[\"Class Name\"] = df[\"Label\"].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "# Apply preprocessing function to training and test datasets\n",
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3609b65b-5e26-4314-8c7e-848bf0a41144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    # Sample rows, selecting num_samples of each Label.\n",
    "    df = (\n",
    "        df.groupby(\"Label\")[df.columns]\n",
    "        .apply(lambda x: x.sample(num_samples))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "\n",
    "    # We have fewer categories now, so re-calibrate the label encoding.\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "    df[\"Encoded Label\"] = df[\"Class Name\"].cat.codes\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "TRAIN_NUM_SAMPLES = 100\n",
    "TEST_NUM_SAMPLES = 25\n",
    "CLASSES_TO_KEEP = \"sci\"  # Class name should contain 'sci' to keep science categories\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e899eb92-edd7-4ffd-b858-a75b5e3e66dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          100\n",
       "sci.electronics    100\n",
       "sci.med            100\n",
       "sci.space          100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e97d51a-6026-4faa-b6ae-e00192243a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class Name\n",
       "sci.crypt          25\n",
       "sci.electronics    25\n",
       "sci.med            25\n",
       "sci.space          25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.value_counts(\"Class Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef69f6-71c4-457f-b33f-e5770466c115",
   "metadata": {},
   "source": [
    "# 2. Create the embeddings\n",
    "\n",
    "In this section, you will generate embeddings for each piece of text using the Gemini API embeddings endpoint. To learn more about embeddings, visit the embeddings guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edca8202-d4de-444b-957f-e594272c7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "from tqdm.rich import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "model = \"models/text-embedding-004\"\n",
    "\n",
    "@retry.Retry(timeout=300.0)\n",
    "def embed_fn(text: str) -> list[float]:\n",
    "    # You will be performing classification, so set task_type accordingly.\n",
    "    embed = client.embeddings.create(input=text,\n",
    "                                     model=model)\n",
    "    time.sleep(0.2)\n",
    "    return embed.data[0].embedding\n",
    "\n",
    "\n",
    "def create_embeddings(df):\n",
    "    df[\"Embeddings\"] = df[\"Text\"].progress_apply(embed_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7e3ca76-7250-4dc2-929f-aebec01752a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b5774695fb46ecad3fef1040043b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmlb/py310env/lib/python3.10/site-packages/tqdm/std.py:885: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  t = cls(total=total, **tqdm_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0945c264fe64c88bb5b17cf13769545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmlb/py310env/lib/python3.10/site-packages/tqdm/std.py:885: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  t = cls(total=total, **tqdm_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Encoded Label</th>\n",
       "      <th>Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Re: Fifth Amendment and Passwords\\n\\nIn articl...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.027680234983563423, 0.04840068146586418, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Re: Once tapped, your code is no good any more...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.051765553653240204, 0.010603193193674088, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>Re: Once tapped, your code is no good any more...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.030571889132261276, 0.010716283693909645, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Re: Off the shelf cheap DES keyseach machine (...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.02225799486041069, 0.003658391535282135, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Re: Secret algorithm [Re: Clipper Chip and cry...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.06348730623722076, 0.05079176649451256, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label Class Name  \\\n",
       "1100  Re: Fifth Amendment and Passwords\\n\\nIn articl...     11  sci.crypt   \n",
       "1101  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n",
       "1102  Re: Once tapped, your code is no good any more...     11  sci.crypt   \n",
       "1103  Re: Off the shelf cheap DES keyseach machine (...     11  sci.crypt   \n",
       "1104  Re: Secret algorithm [Re: Clipper Chip and cry...     11  sci.crypt   \n",
       "\n",
       "      Encoded Label                                         Embeddings  \n",
       "1100              0  [-0.027680234983563423, 0.04840068146586418, -...  \n",
       "1101              0  [0.051765553653240204, 0.010603193193674088, -...  \n",
       "1102              0  [0.030571889132261276, 0.010716283693909645, -...  \n",
       "1103              0  [0.02225799486041069, 0.003658391535282135, -0...  \n",
       "1104              0  [0.06348730623722076, 0.05079176649451256, -0....  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_embeddings(df_train)\n",
    "df_test = create_embeddings(df_test)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c767d-dc27-48ea-8a69-8d2ae97b38f3",
   "metadata": {},
   "source": [
    "# 3. Build a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "765b4115-8468-4da2-8373-0f540727d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.3539885741013746, Train Acc: 0.7025\n",
      "Validation Accuracy: 0.86\n",
      "Epoch 2/20, Train Loss: 1.2009927401175866, Train Acc: 0.9075\n",
      "Validation Accuracy: 0.89\n",
      "Epoch 3/20, Train Loss: 0.972532318188594, Train Acc: 0.97\n",
      "Validation Accuracy: 0.92\n",
      "Epoch 4/20, Train Loss: 0.8394117997242854, Train Acc: 0.975\n",
      "Validation Accuracy: 0.94\n",
      "Epoch 5/20, Train Loss: 0.7929117862994854, Train Acc: 0.985\n",
      "Validation Accuracy: 0.93\n",
      "Epoch 6/20, Train Loss: 0.7766444820624131, Train Acc: 0.99\n",
      "Validation Accuracy: 0.95\n",
      "Epoch 7/20, Train Loss: 0.765714012659513, Train Acc: 0.995\n",
      "Validation Accuracy: 0.94\n",
      "Epoch 8/20, Train Loss: 0.7613680775348957, Train Acc: 0.9975\n",
      "Validation Accuracy: 0.92\n",
      "Epoch 9/20, Train Loss: 0.7552154614375188, Train Acc: 0.9975\n",
      "Validation Accuracy: 0.93\n",
      "Epoch 10/20, Train Loss: 0.7540987179829524, Train Acc: 0.9975\n",
      "Validation Accuracy: 0.92\n",
      "Epoch 11/20, Train Loss: 0.7510198171322162, Train Acc: 1.0\n",
      "Validation Accuracy: 0.94\n",
      "Epoch 12/20, Train Loss: 0.7489657631287208, Train Acc: 1.0\n",
      "Validation Accuracy: 0.92\n",
      "Epoch 13/20, Train Loss: 0.7480548620223999, Train Acc: 1.0\n",
      "Validation Accuracy: 0.93\n",
      "Epoch 14/20, Train Loss: 0.7473379556949322, Train Acc: 1.0\n",
      "Validation Accuracy: 0.93\n",
      "Epoch 15/20, Train Loss: 0.7467341698133029, Train Acc: 1.0\n",
      "Validation Accuracy: 0.93\n",
      "Epoch 16/20, Train Loss: 0.7463762622613174, Train Acc: 1.0\n",
      "Validation Accuracy: 0.93\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, input_size: int, num_classes: int):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_probs = nn.Linear(input_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_probs(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Extract embedding size and class count from the data\n",
    "embedding_size = len(df_train[\"Embeddings\"].iloc[0])\n",
    "num_classes = len(df_train[\"Class Name\"].unique())\n",
    "\n",
    "# Convert the data into NumPy arrays and then to PyTorch tensors\n",
    "y_train = torch.tensor(df_train[\"Encoded Label\"].values, dtype=torch.long)\n",
    "x_train = torch.tensor(np.stack(df_train[\"Embeddings\"].values), dtype=torch.float32)\n",
    "y_val = torch.tensor(df_test[\"Encoded Label\"].values, dtype=torch.long)\n",
    "x_val = torch.tensor(np.stack(df_test[\"Embeddings\"].values), dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "classifier = ClassificationModel(input_size=embedding_size, num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCHS = 20\n",
    "early_stop_patience = 10\n",
    "best_val_acc = 0\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    classifier.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == y_batch).sum().item()\n",
    "        total_samples += y_batch.size(0)\n",
    "\n",
    "    train_acc = train_correct / total_samples\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {train_loss/len(train_loader)}, Train Acc: {train_acc}\")\n",
    "\n",
    "    # Validation\n",
    "    classifier.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            outputs = classifier(x_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == y_batch).sum().item()\n",
    "            val_total += y_batch.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Validation Accuracy: {val_acc}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= early_stop_patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a762cc-a851-4d2c-8be8-3b748e7bf361",
   "metadata": {},
   "source": [
    "# 4. Try a custom prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "885c78a3-eb6f-4b4f-a8ba-5b1a77175fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example avoids any space-specific terminology to see if the model avoids\n",
    "# biases towards specific jargon.\n",
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "embedded = embed_fn(new_text)\n",
    "\n",
    "inp = torch.Tensor([embedded])\n",
    "with torch.no_grad():\n",
    "    outputs = classifier(inp).numpy()[0]\n",
    "    for idx, category in enumerate(df_test[\"Class Name\"].cat.categories):\n",
    "        print(f\"{category}: {outputs[idx] * 100:0.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
